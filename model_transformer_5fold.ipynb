{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dYxpVTQDDex5",
    "outputId": "4754ea58-e3f9-402b-f93f-dcdb4dbb0939"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import Model\n",
    "from keras.layers import Conv1D, Embedding, Input, Bidirectional, CuDNNLSTM, Dense, Concatenate, Masking, LSTM, SpatialDropout1D\n",
    "from keras.layers import BatchNormalization, Dropout, Activation, Add\n",
    "from keras.layers import GlobalMaxPool1D, GlobalAveragePooling1D, GlobalAvgPool1D, GlobalMaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, Callback\n",
    "from keras.utils import to_categorical\n",
    "from keras_radam import RAdam\n",
    "from keras_lookahead import Lookahead\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "\n",
    "from keras_multi_head import MultiHead, MultiHeadAttention\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from keras_position_wise_feed_forward import FeedForward\n",
    "from keras_layer_normalization import LayerNormalization\n",
    "\n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "KTF.set_session(session)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras-rectified-adam\n",
    "# !pip install keras-lookahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    tf.set_random_seed(seed)\n",
    "\n",
    "seed = 2020\n",
    "fix_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c7LMAeCXD3Tr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('raw_data/train_set.csv', sep='\\t')\n",
    "df_test = pd.read_csv('raw_data/test_a.csv', sep='\\t')\n",
    "df_data = df_train.append(df_test)\n",
    "df_data = df_data.reset_index(drop=True)\n",
    "df_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2967 6758 339 2021 1854 3731 4109 3792 4149 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.0</td>\n",
       "      <td>4464 486 6352 5619 2465 4802 1452 3137 5778 54...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>7346 4068 5074 3747 5681 6093 1777 2226 7354 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7159 948 4866 2109 5520 2490 211 3956 5520 549...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3646 3055 3055 2490 4659 6065 3370 5814 2465 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0    2.0  2967 6758 339 2021 1854 3731 4109 3792 4149 15...\n",
       "1   11.0  4464 486 6352 5619 2465 4802 1452 3137 5778 54...\n",
       "2    3.0  7346 4068 5074 3747 5681 6093 1777 2226 7354 6...\n",
       "3    2.0  7159 948 4866 2109 5520 2490 211 3956 5520 549...\n",
       "4    3.0  3646 3055 3055 2490 4659 6065 3370 5814 2465 5..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pwyczuurF9zl",
    "outputId": "2c9cff1e-5961-4d5f-8a64-582ac0e3e6db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate seqs\n"
     ]
    }
   ],
   "source": [
    "max_words_num = None\n",
    "seq_len = 1000\n",
    "embedding_dim = 128\n",
    "col = 'text'\n",
    "\n",
    "print('Generate seqs')\n",
    "os.makedirs('seqs', exist_ok=True)\n",
    "seq_path = 'seqs/seqs_{}_{}.npy'.format(max_words_num, seq_len)\n",
    "word_index_path = 'seqs/word_index_{}_{}.npy'.format(max_words_num, seq_len)\n",
    "if not os.path.exists(seq_path) or not os.path.exists(word_index_path):\n",
    "    tokenizer = text.Tokenizer(num_words=max_words_num, lower=False, filters='')\n",
    "    tokenizer.fit_on_texts(df_data[col].values.tolist())\n",
    "    seqs = sequence.pad_sequences(tokenizer.texts_to_sequences(df_data[col].values.tolist()), maxlen=seq_len,\n",
    "                                  padding='post', truncating='pre')\n",
    "    word_index = tokenizer.word_index\n",
    "        \n",
    "    np.save(seq_path, seqs)\n",
    "    np.save(word_index_path, word_index)\n",
    "\n",
    "else:\n",
    "    seqs = np.load(seq_path)\n",
    "    word_index = np.load(word_index_path, allow_pickle=True).item()\n",
    "    \n",
    "# print('Generate embedding')\n",
    "# os.makedirs('embedding', exist_ok=True)\n",
    "# embedding_path = 'embedding/w2v_{}_{}.m'.format(col, embedding_dim)\n",
    "# if not os.path.exists(embedding_path):\n",
    "#     print('Training w2v')\n",
    "#     model = Word2Vec([[word for word in senetnce.split(' ')] for senetnce in df_data[col].values],\n",
    "#                       size=embedding_dim, window=20, workers=32, seed=seed, min_count=1, sg=1, hs=1)\n",
    "\n",
    "#     model.save(embedding_path)\n",
    "# else:\n",
    "#     model = Word2Vec.load(embedding_path)\n",
    "\n",
    "embedding = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "# for word, i in tqdm(word_index.items()):\n",
    "#     embedding_vector = model[word] if word in model else None\n",
    "#     if embedding_vector is not None:\n",
    "#         embedding[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0     38918\n",
       "1.0     36945\n",
       "2.0     31425\n",
       "3.0     22133\n",
       "4.0     15016\n",
       "5.0     12232\n",
       "6.0      9985\n",
       "7.0      8841\n",
       "8.0      7847\n",
       "9.0      5878\n",
       "10.0     4920\n",
       "11.0     3131\n",
       "12.0     1821\n",
       "13.0      908\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('model', exist_ok=True)\n",
    "os.makedirs('sub', exist_ok=True)\n",
    "os.makedirs('prob', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_index = df_data[df_data['label'].notnull()].index.tolist()\n",
    "test_index = df_data[df_data['label'].isnull()].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(emb, seq_len):\n",
    "    inp = Input(shape=(seq_len,))\n",
    "\n",
    "    emb_layer = Embedding(\n",
    "        input_dim=emb.shape[0],\n",
    "        output_dim=emb.shape[1],\n",
    "        input_length=seq_len)(inp)\n",
    "\n",
    "    sdrop = SpatialDropout1D(rate=0.2)\n",
    "    emb_layer = sdrop(emb_layer)\n",
    "\n",
    "    mha1 = MultiHeadAttention(head_num=16)(emb_layer)\n",
    "    mha1 = Dropout(0.01)(mha1)\n",
    "    mha1 = Add()([emb_layer, mha1])\n",
    "    mha1 = LayerNormalization()(mha1)\n",
    "    mha1 = Dropout(0.01)(mha1)\n",
    "    mha1_ff = FeedForward(128)(mha1)\n",
    "    mha1_out = Add()([mha1, mha1_ff])\n",
    "    mha1_out = LayerNormalization()(mha1_out)\n",
    "\n",
    "    mha2 = MultiHeadAttention(head_num=16)(mha1_out)\n",
    "    mha2 = Dropout(0.01)(mha2)\n",
    "    mha2 = Add()([mha1_out, mha2])\n",
    "    mha2 = LayerNormalization()(mha2)\n",
    "    mha2 = Dropout(0.01)(mha2)\n",
    "    mha2_ff = FeedForward(128)(mha2)\n",
    "    mha2_out = Add()([mha2, mha2_ff])\n",
    "    mha2_out = LayerNormalization()(mha2_out)\n",
    "    \n",
    "    lstm = Bidirectional(LSTM(128, return_sequences=True))(mha2_out)\n",
    "\n",
    "    avg_pool = GlobalAveragePooling1D()(lstm)\n",
    "    max_pool = GlobalMaxPool1D()(lstm)\n",
    "\n",
    "    x = Concatenate()([avg_pool, max_pool])\n",
    "\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    out = Dense(14, activation='softmax')(x)\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer=Adam(1e-4),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator(Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        super().__init__()\n",
    "        self.best_val_f1 = 0.\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "    def evaluate(self):\n",
    "        y_true = self.y_val\n",
    "        y_pred = self.model.predict(self.x_val).argmax(axis=1)\n",
    "        f1 = f1_score(y_true, y_pred, average='macro')\n",
    "        return f1\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_f1 = self.evaluate()\n",
    "        if val_f1 > self.best_val_f1:\n",
    "            self.best_val_f1 = val_f1\n",
    "        logs['val_f1'] = val_f1\n",
    "        print(f'val_f1: {val_f1:.5f}, best_val_f1: {self.best_val_f1:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 160000 samples, validate on 40000 samples\n",
      "Epoch 1/30\n",
      "160000/160000 [==============================] - 10189s 64ms/step - loss: 0.7095 - accuracy: 0.7962 - val_loss: 0.3223 - val_accuracy: 0.9039\n",
      "val_f1: 0.85578, best_val_f1: 0.85578\n",
      "\n",
      "Epoch 00001: val_f1 improved from -inf to 0.85578, saving model to model/transformer_0.h5\n",
      "Epoch 2/30\n",
      "160000/160000 [==============================] - 10523s 66ms/step - loss: 0.3038 - accuracy: 0.9104 - val_loss: 0.2764 - val_accuracy: 0.9185\n",
      "val_f1: 0.90114, best_val_f1: 0.90114\n",
      "\n",
      "Epoch 00002: val_f1 improved from 0.85578 to 0.90114, saving model to model/transformer_0.h5\n",
      "Epoch 3/30\n",
      "160000/160000 [==============================] - 9744s 61ms/step - loss: 0.2495 - accuracy: 0.9241 - val_loss: 0.2176 - val_accuracy: 0.9341\n",
      "val_f1: 0.91846, best_val_f1: 0.91846\n",
      "\n",
      "Epoch 00003: val_f1 improved from 0.90114 to 0.91846, saving model to model/transformer_0.h5\n",
      "Epoch 4/30\n",
      " 85632/160000 [===============>..............] - ETA: 1:06:39 - loss: 0.2141 - accuracy: 0.9340"
     ]
    }
   ],
   "source": [
    "bs = 32\n",
    "monitor = 'val_f1'\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "for fold_id, (train_index, val_index) in enumerate(kfold.split(all_index, df_data.iloc[all_index]['label'])):\n",
    "    train_x = seqs[train_index]\n",
    "    val_x = seqs[val_index]\n",
    "\n",
    "    label = df_data['label'].values\n",
    "    train_y = label[train_index]\n",
    "    val_y = label[val_index]\n",
    "    \n",
    "    model_path = 'model/transformer_{}.h5'.format(fold_id)\n",
    "    checkpoint = ModelCheckpoint(model_path, monitor=monitor, verbose=1, save_best_only=True, mode='max', save_weights_only=True)\n",
    "    earlystopping = EarlyStopping(monitor=monitor, patience=5, verbose=1, mode='max')\n",
    "    reduce_lr = ReduceLROnPlateau(monitor=monitor, factor=0.1, patience=2, mode='max', verbose=1)\n",
    "    \n",
    "    model = build_model(embedding, seq_len)\n",
    "    model.fit(train_x, train_y, batch_size=bs, epochs=30,\n",
    "              validation_data=(val_x, val_y),\n",
    "              callbacks=[Evaluator(validation_data=(val_x, val_y)), checkpoint, reduce_lr, earlystopping], verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_pred = np.zeros((len(all_index), 14))\n",
    "test_pred = np.zeros((len(test_index), 14))\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "for fold_id, (train_index, val_index) in enumerate(kfold.split(all_index, df_data.iloc[all_index]['label'])):\n",
    "    model = build_model(embedding, seq_len)\n",
    "    model_path = 'model/transformer_{}.h5'.format(fold_id)\n",
    "    model.load_weights(model_path)\n",
    "    \n",
    "    val_x = seqs[val_index]\n",
    "    prob = model.predict(val_x, batch_size=bs, verbose=1)\n",
    "    oof_pred[val_index] = prob\n",
    "    \n",
    "    test_x = seqs[test_index]\n",
    "    prob = model.predict(test_x, batch_size=bs, verbose=1)\n",
    "    test_pred += prob / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_oof = df_data.loc[all_index][['label']]\n",
    "df_oof['predict'] = np.argmax(oof_pred, axis=1)\n",
    "f1score = f1_score(df_oof['label'], df_oof['predict'], average='macro')\n",
    "print(f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9363675328073761"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('prob/sub_5fold_transformer_{}.npy'.format(f1score), test_pred)\n",
    "np.save('prob/oof_5fold_transformer_{}.npy'.format(f1score), oof_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['label'] = np.argmax(test_pred, axis=1)\n",
    "sub.to_csv('sub/transformer_{}.csv'.format(f1score), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lstm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_tensorflow_py3",
   "language": "python",
   "name": "conda_tensorflow_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
